# Week 3 Plan: Machine Learning Concepts – Supervised & Unsupervised Learning

---

## **Day 1-2: Introduction to Supervised Learning – Linear Regression**
- **Concepts to Cover:**
  - **Linear Regression**: Understand the concept of fitting a linear model to data, minimizing the residual sum of squares (RSS).
  - **Cost Function**: Learn about the Mean Squared Error (MSE) cost function and gradient descent to minimize it.
  - **Model Evaluation**: Learn how to evaluate the performance of linear regression models using metrics like R² (R-squared).
- **Resources:**
  - Watch tutorials on linear regression (e.g., from Andrew Ng’s Machine Learning course).
  - Practice implementing linear regression using Python (e.g., from scratch or using `scikit-learn`).
  
**Study Time Breakdown (8 hrs/day)**:
- **Theory (4 hrs)**: Watch videos on linear regression, cost function, and gradient descent.
- **Practice (4 hrs)**: Implement linear regression from scratch or with `scikit-learn` on a real dataset (e.g., predicting house prices).

---

## **Day 3-4: Introduction to Logistic Regression**
- **Concepts to Cover:**
  - **Logistic Regression**: Understand how logistic regression is used for binary classification.
  - **Sigmoid Function**: Learn how the sigmoid function works to map the output between 0 and 1.
  - **Model Evaluation**: Learn about evaluation metrics for classification such as accuracy, precision, recall, and F1 score.
- **Resources:**
  - Watch tutorials on logistic regression (Andrew Ng’s course, StatQuest).
  - Implement logistic regression using `scikit-learn` on a classification dataset (e.g., Titanic dataset for survival prediction).

**Study Time Breakdown (8 hrs/day)**:
- **Theory (4 hrs)**: Watch videos on logistic regression and classification metrics.
- **Practice (4 hrs)**: Implement logistic regression on a classification problem using `scikit-learn`.

---

## **Day 5-6: Introduction to Decision Trees and Random Forests**
- **Concepts to Cover:**
  - **Decision Trees**: Learn how decision trees are built, how they work for classification and regression, and how to evaluate them.
  - **Random Forests**: Understand the concept of ensemble learning and how random forests aggregate decision trees to improve accuracy.
  - **Overfitting and Pruning**: Learn how decision trees are prone to overfitting and how to prune them to reduce complexity.
- **Resources:**
  - Watch tutorials on decision trees and random forests (e.g., StatQuest).
  - Practice implementing decision trees and random forests using `scikit-learn`.

**Study Time Breakdown (8 hrs/day)**:
- **Theory (4 hrs)**: Watch videos on decision trees and random forests, focusing on their algorithms and applications.
- **Practice (4 hrs)**: Implement decision trees and random forests using real-world datasets.

---

## **Day 7: Recap & Mini Project**
- **Review**: Go over everything you've learned this week, focusing on any concepts or algorithms that are unclear.
- **Mini Project**:
  - Use a real dataset (e.g., **Kaggle Titanic dataset**) to:
    - Build and evaluate a **Logistic Regression** model.
    - Build and evaluate a **Decision Tree** model.
    - Compare the results and see which model performs better.
  - Use **accuracy**, **precision**, and **recall** to evaluate the models and visualize the results using **Matplotlib** and **Seaborn**.

**Study Time Breakdown (8 hrs)**:
- **Review & Recap (4 hrs)**: Go over the algorithms and ensure you understand how they work.
- **Mini Project (4 hrs)**: Build and compare models on a real dataset, documenting the process.

---

### **Additional Tips for Week 3**:
- **Practice Coding**: As you learn about different machine learning algorithms, try to implement them both from scratch and using libraries like `scikit-learn`.
- **Explore Different Datasets**: Use datasets from **Kaggle** or **UCI Machine Learning Repository** to practice these algorithms.
- **Understand Overfitting**: Learn about overfitting and underfitting by trying to apply models on different-sized datasets.
- **Model Evaluation**: Make sure to practice using evaluation metrics for classification and regression (e.g., accuracy, confusion matrix, AUC-ROC curve).
- **Stay Consistent**: Spend time reflecting on what you've learned by reviewing notes and practicing regularly.

By the end of Week 3, you’ll have a solid understanding of key supervised learning algorithms, including linear regression, logistic regression, decision trees, and random forests. You'll also gain hands-on experience with implementing and evaluating these models.
